# 평가(오차행렬, 정확도, 정밀도, 재현율, F1 스코어)

<br>

### 정확도

<br>

정확도란 전체 예측 데이터 건수에서 예측 결과가 동일한 건수에 대한 비율을 나타내는 평가 지표이다.

정확도는 직관적으로 모델에 대한 평가를 알 수 있지만 간단한만큼 단점도 존재한다.

이진분류의 경우 정확도는 모델의 성능을 왜곡하여 표현할 수도 있기 때문에 정확도만으로 모델을 평가해서는 안된다.

불균형한 레이블 값 분포에서 모델의 성능을 판단할 때는 정확도 뿐만 아니라 다른 평가 지표도 함께 고려해야한다.

<br>

모델 성능 왜곡에 대한 예시로

주머니 안에 10개의 공이 있고 9개의 공이 검은 공이라고 하자.

모델을 학습시키지도 않고 그냥 '10개 모두 검은 공이다'라고 예측하면

정확도가 90퍼센트가 나오게 된다.

<br>

---

### 오차 행렬(Confusion Matrix)

<br>

| ↓실제 클래스 / → 예측 클래스 |    Negative(0)     |    Positive(1)     |
| :--------------------------: | :----------------: | :----------------: |
|         Negative(0)          | TN(True Negative)  | FP(False Positive) |
|         Positive(1)          | FN(False Negative) | TP(True Positive)  |

오차행렬은 이진 분류의 예측 오류가 얼마인지와 어떤 유형의 예측 오류가 발생했는지를 나타내는 지표이다.

TN : Negative라고 예측했을 때 실제 값이 Negative인 경우

FN : Negative라고 예측했을 때 실제 값이 Positive인 경우

FP: Positive라고 예측했을 때 실제 값이 Negative인 경우

TP : Positive라고 예측했을 때 실제 값이 Positive인 경우

<br>

---

### 정밀도와 재현율(Precision & Recall)

<br>

정밀도는 Positive로 예측한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 말함

``정밀도 = TP / (FP + TP)``

<br>

재현율은 실제 Positive인 값인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 말함

``재현율 = TP / (FN + TP)``

<br>

정밀도와 재현율은 정확도와 다르게 예측이 틀린 데이터도 포함하여 계산하기 때문에 정확도에서 발생하는 문제를 보완할 수 있다.

가급적 양성이라고 확인하는 것이 나은 경우 재현율을 사용하고(암 진단, 금융사기 판별 등)

그 반대는 정밀도를 사용한다(스팸 메일 등).

<br>

분류의 결정 임계값을 조정하여 정밀도와 재현율의 수치를 조정할 수 있다.

정밀도와 재현율은 서로 트레이드 오프 관계이기 때문에 상황에 맞게 임계값을 잘 설정해줄 필요가 있다.

보통 정밀도와 재현율이 비슷하면 좋은 성능의 모델이라고 판단한다.

<br>

---

### F1 스코어

<br>

F1 스코어는 정밀도와 재현율을 결합한 지표이다. 

F1 스코어는 정밀도와 재현율이 비슷할 때 높은 수치를 나타낸다.

``F1 score = 2 * {(정밀도 * 재현율) / (정밀도 + 재현율)}``

<br>

---

### ROC 커브와 AUC

<br>

일반적으로 의학 분야에서 많이 사용되지만 머신러닝의 이진 분류 모델의 성능을 판단할 때 중요하게 사용되는 평가 지표.

ROC 커브의 아래 면적을 AUC라고 표현하고 AUC 스코어 값이 1에 가까울 수록 좋은 모델이라고 판단한다.

[링크](https://bioinfoblog.tistory.com/221) 해당 블로그에 ROC커브와 AUC 면적을 간단한 설명을 볼 수 있다.

