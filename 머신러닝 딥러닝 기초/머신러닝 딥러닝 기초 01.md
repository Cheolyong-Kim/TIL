# 머신러닝 딥러닝 기초 01

<br/>

### 인공지능

> 인간과 컴퓨터는 각각 강점과 약점을 가지고 있다. 인공지능이 탑재된 컴퓨터는 논리적으로 추론할 수도 있으며 학습도 가능하다. 인간은 계산은 느리지만 창의적으로 문제를 해결할 수 있다. 인간은 인공지능 컴퓨터를 통해서 자신의 약점을 극복할 수 있다.

<br/>

- 인공지능의 정의

  : 인공 지능이란 인간의 인지적인 기능을 흉내내 문제를 해결하기 위해 학습하고 이해하는 기계이다.

  <br/>

- 인공지능의 특징

  1. 학습
     - 과거의 패턴들로부터 학습할 수 있는 능력을 가지고 있다.
  2. 문제해결
     - 복잡한 문제를 분석하고 해결할 수 있는 능력을 가지고 있다.
  3. 빅데이터
     - 아주 큰 용량의 변화하는 데이터를 처리할 수 있다.
  4. 추론
     - 주위의 상황으로부터 추론할 수 있는 능력을 가지고 있다.

  <br/>

- 인공지능 vs 기계학습 vs 딥러닝

  1.  인공지능
     - 인간처럼 학습하고 추론하는 프로그램 연구
  2. 기계학습
     - 인공지능의 한 분야로서 프로그래밍 없이 스스로 학습하는 프로그램 연구
  3. 딥러닝
     - 인공 신경망 등을 사용하여 빅데이터로부터 학습하는 프로그램 연구

  인공지능 > 기계학습 > 딥러닝 순으로 포함하는 관계라고 할 수 있다.

<br/>

---

### 머신러닝

> 컴퓨터가 민간에 널리 보급되기 시작하면서 데이터들이 범람하게 되고 그 빅데이터들을 다루기 위한 도구들이 출현하면서 머신러닝 분야가 발전하게 되었다.

<br/>

- 머신러닝

  - 기존의 프로그래밍 기법들은 사람이 프로그래밍 규칙을 지정한 후 데이터를 입력하여 결과를 얻는 구조였다.
  - 머신러닝 기반 프로그래밍에서는 결과와 데이터를 입력하면 데이터와 결과로부터 규칙을 뽑아내는 구조이다.

  <br/>

- 알고리즘 vs 머신러닝

  - 알고리즘 : 어떠한 문제를 해결하기 위한 일련의 절차나 방법
  - 머신러닝 : 기계가 패턴을 학습하여 자동화하는 알고리즘

  <br/>

- 머신러닝 vs 딥러닝

  - 머신러닝 
    - 데이터를 컴퓨터에 학습시켜 그 패턴과 규칙을 컴퓨터가 스스로 학습하도록 만드는 기술
    - 이전에는 사람이 지식을 직접 데이터베이스화한 후 컴퓨터가 처리하도록 프로그램으로 만듦 (전문가 시스템)
    - 머신러닝은 데이터를 분류하는 수학적 모델을 프로그래밍하여, 데이터만 입력하면 이미 만들어진 수학 모델이 규칙으로 적용되어 여러 문제를 풀 수 있음.
  - 딥러닝
    - 머신러닝 기법 중 신경망을 기반으로 사물이나 데이터를 군집화하거나 분류하는 데 사용하는 기술
  - 딥러닝이 급속도로 발전함에 따라 전통적 머신러닝과 최근 많이 사용되는 딥러닝을 병렬 관계로 보기도 한다.

  <br/>

- 빅데이터

  - 기존의 데이터베이스로는 수집, 저장, 분석을 수행하기 어려울 만큼 방대한 양의 데이터
  - 빅데이터 시스템 : 빅데이터를 다루기 위한 시스템
  - 빅데이터 엔지니어링 : 빅데이터를 다루는 방법
    - 머신러닝과 별개로 발전해왔으나 대용량 데이터가 학습 성능에 크게 영향을 미치는 오늘날 머신러닝 분야에서 의미 있게 사용됨.

  <br/>

- 모델

  - 상관관계를 식으로 표현한 것을 말한다.
    $$
    y = ax + b
    $$

  - 알고리즘을 통해 적합한 a와 b를 찾는 것으로 다음에 입력되는 데이터의 결과를 예측할 수 있다.

  <br/>

- 학습 방법

  1. 지도학습
     - 문제와 답을 함께 학습
     - 종류로 회귀, 분류 등이 있다
       - 회귀 : 연속형 값인 y의 특징을 찾아 데이터 x를 사용하여 y값을 예측
       - 분류 : 이산형 값인 y의 특징을 찾아 데이터 x를 사용하여 y값을 예측
  2. 비지도학습
     - 조력자의 도움 없이 컴퓨터 스스로 학습
     - 컴퓨터가 훈련 데이터를 이용하여 데이터들 간의 규칙성을 찾아냄
     - 종류로 군집 등이 있다.
       - 군집 : y값이 주어지지 않고, 데이터의 특징이 유사한 값들의 모임을 군집으로 표현
  3. 강화학습
     - 컴퓨터가 세상에 존재하는 규칙을 스스로 시뮬레이션하면서 게임처럼 규칙을 학습
     - 보상과 처벌을 통해 학습시킴

  <br/>

- 머신러닝의 4가지 단계

  1. 훈련 데이터 수집
  2. 입력 데이터 분석 및 준비
  3. 학습 : 모델을 만들거나 배우는 것을 의미
  4. 예측 및 테스트 : 학습된 모델을 레이블이 없는 샘플에 적용하는 것을 의미. 즉 학습된 모델을 사용하여 유용한 예측을 해내는 것

  <br/>

- 특징을 선택할 때 주의사항

  - 50%에 가까운 확률을 가지는 특징들은 제외
  - 개체들을 구분하는 데 효과가 없는 중복된 특징들도 제외 (ex. 개와 고양이의 이동 속도, 털의 길이, 눈의 색상 등)
  - 확실하게 개체들을 독립적으로 구분할 수 있는 특징들을 선택
  - 다수 개의 특징들을 사용하면 더욱 효과적

  <br/>

- 레이블

  - ``y = f(x)`` 에서 y변수에 해당
  - 예를 들어, 농작물의 향후 가격, 사진에 표시되는 동물의 종류, 동영상의 의미 등 무엇이든지 레이블이 될 수 있다.

  <br/>

- 샘플, 또는 예제

  - 샘플은 기계 학습에 주어지는 특정한 예이다. ``y = f(x)``에서 x에 해당한다. 레이블이 있는 샘플도 있고 레이블이 없는 샘플도 있다.

  <br/>

- 특징과 결과

  - 특징 : 훈련을 위한 입력

  - 라벨 : 결과

  - 대표적인 지도학습 방식

  - 답을 알려주고 학습함

  - 예시 (무게가 250g이고 표면이 울퉁불퉁하면 오렌지이다 를 학습)

    |    특징     |              |  결과  |
    | :---------: | :----------: | :----: |
    | **무게(g)** | **표면상태** |        |
    |     270     |   울퉁불퉁   | 오렌지 |
    |     250     |   울퉁불퉁   | 오렌지 |
    |     220     |     매끈     |  사과  |
    |     240     |     매끈     |  사과  |

    - 데이터 수집
      - 입력 특징을 2차원 리스트로 feature 변수에 저장
      - 결과는 labels 변수에 리스트형으로 저장
    - 데이터 준비 및 분석
      - 표면의 상태를 문자열에서 숫자로 변환해야 함
      - feature에서 ''울퉁불퉁''은 0으로 ''매끈''은 1로 지정
      - labels에서 '오렌지'는 0으로 '사과'는 1로 설정
    - 학습
      - sklearn에서 제공하는 DecisionTreeClassifier()를 이용
      - clf.fit(features, labels)에 의해 실행
      - features와 labels로 훈련한 결과를 tree 형태의 구분자로 생성

  <br/>

- 결정트리 학습 모델(Decision Tree Learning Model)

  - 어떤 항목에 대한 목표값을 연결해주는 예측 모델로써 결정트리를 사용하는 방식
  - 의사결정 규칙과 그 결과들을 트리 구조로 생성

  <br/>

- 회귀

  - 독립변수 x와 종속변수 y의 관계를 함수식으로 설명
  - 추세선을 표현하는 수학적 모델을 만드는 기법
  - 실수 입력 x와 실수 출력 y가 주어질 때, 입력에서 추력으로의 매핑 함수를 학습하는 것이라 할 수 있다.

  <br/>

- 분류

  - 데이터를 어떤 기준에 따라 나눔
  - 입력을 두 개 이상의 레이블로 분할하는 것
  - 해당 모델을 학습시킬 때 레이블을 제공해야 한다.
  - 이진 분류 : 2개의 값 중 1개를 분류
  - 다중 분류 : 3개 이상 분류 실행
  - 분류를 수행하기 위한 일반적인 알고리즘에는 신경망, knn, SVM, 의사 결정 트리 등이 포함된다.

<br/>

- 클러스터링(군집화)

  - 데이터간 거리를 계산하여서 입력을 몇 개의 그룹으로 나누는 방법
  - 비지도학습의 대표적인 방법

  <br/>

- 머신러닝의 장점

  1. 프로그래밍 시간을 줄일 수 있다.

     - 많은 데이터만 있다면 학습시켜서 빠른 시간 안에 신뢰성있는 프로그램을 완성할 수 있다.

  2. 맞춤형 제품을 쉽게 개발할 수 있다.

     - 각국의 언어 맞춤법 수정 프로그램의 예제로 들면
     - 각 언어마다 새로 맞춤법 수정 방식을 작성하려면 엄청난 시간이 필요함
     - 머신 러닝을 사용하면 데이터만 많으면 쉽게 만들 수 있다.

  3. 알고리즘이 떠오르지 않는 문제들을 해결할 수 있다.

     - 알고리즘을 굳이 생각하지 않아도 많은 데이터만 보여주면 문제가 해결된다.

<br/>

---

### 데이터

<br/>

- 데이터

  - 데이터는 어떤 값들의 모음이다
  - 값이 어떻게 모여 있는지에 따라 크게 정형 데이터, 반정형 데이터, 비정형 데이터로 나눠진다.
  - 데이터 과학에서는 주로 정형 데이터를 사용한다
  - 반정형 데이터나 비정형 데이터를 다룬다 하더라도 결국 정형화하여 분석한다
  - 정형 데이터는 행과 열이 있는 형태로 값을 모아 놓은 데이터이다.

  <br/>

- 텍스트 마이닝으로 살펴본 비정형 데이터의 분석

  - 최근에는 비정형 데이터에 대한 관심이 크게 증가하고 있다.
  - 대부분의 데이터는 비정형으로 이루어져있기 때문
  - 텍스트 데이터에 대한 활용이 많이 이뤄지고 있다.
  - 이러한 텍스트로 주어지는 비정형 데이터는 디지털화된 데이터임을 전제로 한다
  - 비정형 텍스트 데이터를 분석하는 것을 텍스트 마이닝이라고 한다.
  - 텍스트 마이닝의 가장 중요한 과정 중 하나는 바로 비정형 텍스트 데이터를 정형화하는 것이다.
  - 비정형 텍스트 데이터를 정형화하는 텍스트 마이닝의 절차
    1. 텍스트 마이닝 대상이 되는 코퍼스를 준비
    2. 코퍼스에 대해 숫자나 문장 부호 등을 제거(영문인 경우 모두 소문자로 변환)
    3. 불용어(stop words) 제거
    4. 어간 추출
    5. DTM(Document Term Matrix, 문헌용어행렬, 정형화된 텍스트 데이터) 생성

<br/>

---

# 선형대수

> 데이터를 다루는 데이터 과학에서는 값이 정량화되어 기록되기 때문에 이러한 정량화된 값을 잘 다루는 것이 아주 중요함. 그에 따라 수학적 접근과 이해의 중요성이 부각되고 있음. 

  <br/>

- 선형대수

  - 주어진 데이터를 어떤 공간으로 표현한 것이라 할 수 있음
  - 데이터를 다루는 머신 러닝에서 필수 불가결한 역할을 함
  - 2차원으로 표현된 데이터를 이해하는 다양한 개념과 방법을 제공하는 것이 바로 선형대수의 역할

  <br/>

- 벡터

  - 방향과 크기를 갖는 직선
  - 2차원에서의 직선이 될 수도 있고, 더 많은 차원에서의 직선으로 표현될수도 있음.
  - 나름의 기준으로 어떤 값을 모음을 한 줄로 표현한 것
  - 세로로 표현하는 경우를 종벡터, 가로로 표현한 경우를 횡벡터라 부름. 종벡터를 더 많이 사용하는 편

  <br/>

- 행렬

  - 숫자를 가로와 세로로 표처럼 늘어 놓은 것을 행렬이라 부름
  - 행렬은 수나 기호, 수식 등을 네모꼴로 배열한 것

  <br/>

- 다항식의 미분

  - 함수의 기울기를 도출하는 방법

  - 중첩된 함수의 미분 : 연쇄 법칙

    - 연쇄법칙은 식이 복잡하고 전개하기 힘든 경우 매우 편리하게 사용할 수 있는 공식

    - ``f(w)=g(w)^2`` 이고 ``g(w)=aw+b`` 일 때
      $$
      \frac{d}{dw}f(g(w))=\frac{df}{dg}\cdot\frac{dg}{dw}
      $$

  <br/>

- 행렬과 벡터의 연산

```python
import numpy as np

a = np.array([2, 1])  # 벡터

print(np.linalg.norm(a))  # 2.23606797749979 (벡터의 크기 계산)
```

<br/>

```python
import numpy as np

m1 = np.array([[1, 2], [3, 4]])  # 행렬

m2 = np.array([[1, 2], [3, 4]])

print(m1 + m2)  # 행렬의 덧셈
print(m1 * m2)  # 행렬 곱 X, 스칼라 곱
```

<br/>

```python
print(np.dot(m1, m2))  # 벡터 내적을 통한 행렬의 곱
```

<br/>

  ```python
  import numpy as np
  
  m_x = np.array([[1, 2, 3]])
  m_y = np.array([[4, 5, 6]])
  
  # print(np.dot(m_x, m_y))  # 행, 열이 맞지 않아서 계산이 안됨
  
  m_y = m_y.T  # m_y의 전치 행렬
  print(m_y)
  
  print(np.dot(m_x, m_y))
  print(m_x.dot(m_y))  # 위와 동일한 연산
  ```

<br/>

- 역행렬을 통한 연립방적식 풀이

```python
import numpy as np
from numpy.linalg import inv

A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
in_A = inv(A)

print(in_A)

# 2x-y=0
# x+y=3

# Y=WX
# W=XY^-1
X = np.array([[2, -1], [1, 1]])
Y = np.array([[0], [3]])
in_X = inv(X)
W = in_X.dot(Y)
print(W)
```

<br/>

---

### 머신러닝 맛보기

> 간단한 예제로 머신러닝을 직접 해본다.

<br/>

- 클러스터링

```python
from sklearn.neighbors import KNeighborsClassifier

# 데이터 수집
A_length = [25.4, 26.5, 27.5, 28.4, 29.0, 29.2, 30.1, 30.5, 31.4, 31.2]
A_weight = [243, 290, 340, 363, 430, 450, 500, 394, 450, 500]
B_length = [5.4, 6.5, 7.5, 8.4, 9.0, 9.2, 9.1, 9.5, 1.4, 1.2]
B_weight = [43, 90, 40, 63, 30, 50, 50, 94, 50, 50]

# 데이터 정리
length = A_length + B_length
weight = A_weight + A_weight
data = [[length, weight] for length, weight in zip(length, weight)]
X = data

# A = 0, B = 1
Y = [0] * 10 + [1] * 10

# 모델 생성
kn = KNeighborsClassifier()

# 학습
kn.fit(X, Y)

# 테스트
print(kn.predict([[30, 400]]), kn.predict([[7, 40]]))
```

<br/>

- 회귀

```python
from sklearn.datasets import *
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression

d = load_digits()

d.images[0].flatten()

t = load_boston()  # 데이터 로드
df = pd.DataFrame(t.data, columns=t.feature_names)
df['가격'] = t.target
x = t.data
y = t.target  # 정답

m = LinearRegression()  # 모델 생성
m.fit(x, y)  # 학습

out_d = m.predict(t.data)
plt.scatter(y, out_d)
plt.show()
```

