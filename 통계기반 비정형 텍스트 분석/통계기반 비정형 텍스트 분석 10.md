# 통계기반 비정형 텍스트 분석 10

<br/>

#### 실습(영어 데이터 전처리기를 클래스로 구현)

<br/>

- 코드

  ```python
  import pandas as pd
  import numpy as np
  from nltk.corpus import stopwords
  from bs4 import BeautifulSoup
  from sklearn.preprocessing import LabelEncoder
  from sklearn.model_selection import train_test_split
  from tensorflow.keras.utils import to_categorical
  from tensorflow.keras.preprocessing.text import Tokenizer
  from tensorflow.keras.preprocessing.sequence import pad_sequences
  import re
  
  class Preprocessor_eng:
      # 클래스 객체 만들 때 data, 학습에 사용할 X데이터의 열 이름, 불용어를 매개변수로 받음
      def __init__(self, data, x_data, stop_words):
          self.data = data
          self.stop_words = stop_words
          
          if self.data.isnull().values.any(): # 데이터에 null값이 있다면 제거
              self.data = self.data.dropna(how = 'any')
          self.data = self.data.drop_duplicates(subset = [x_data])  # 중복된 데이터 제거
      
      # 데이터 확인용
      def print_data(self):
          print(self.data) 
      
      # 전처리 메소드 (학습에 사용할 X데이터의 열 이름, 불용어 처리 여부를 매개변수로 받음)
      def preprocessor(self, x_data, remove_stopwords = True):
          def preprocessing(X_text, remove_stopwords):
              X_text = BeautifulSoup(X_text, 'lxml').get_text()
              X_text = re.sub("[^a-zA-Z]", " ", X_text)
              words = X_text.lower().split()
              if remove_stopwords:
                  stops = set(self.stop_words)
                  words = [w for w in words if not w in stops]
                  clean_text = ' '.join(words)
              else:
                  clean_text = ' '.join(words)
              return clean_text
      
          self.data['clean_X'] = self.data[x_data].apply(lambda x: preprocessing(X_text = x, remove_stopwords = remove_stopwords))
          self.data['clean_X'] = self.data['clean_X'].str.replace("[^a-zA-Z0-9 ]", "")
          self.data['clean_X'] = self.data['clean_X'].str.replace('^ +', "")
          self.data['clean_X'].replace('', np.nan, inplace = True)
          self.data = self.data.dropna(how = 'any')
      
      # 데이터 분류 메소드(학습에 사용할 Y데이터의 열 이름, 타겟데이터가 문자열인지 아닌지, 이중분류인지 아닌지를 매개변수로 받음)
      def data_classification(self, y_data_column, isstr = False, isbin = True):
          if isstr:
              self.data['encoder_y'] = LabelEncoder().fit_transform(self.data[y_data_column])
              if isbin:
                  Y = np.array(self.data['encoder_y'])
              else:
                  Y = to_categorical(self.data['encoder_y'])
          else:
              if isbin:
                  Y = np.array(self.data[y_data_column])
              else:
                  Y = to_categorical(self.data[y_data_column])
          X = self.data['clean_X']
          
          x_data, tt_x, y_data, tt_y = train_test_split(X, Y, test_size = 0.3, random_state = 0)
          t_x, v_x, t_y, v_y = train_test_split(x_data, y_data, test_size = 0.2, random_state = 0)
          
          tk = Tokenizer()
          tk.fit_on_texts(t_x)
          n = len([d for d in sorted(list(tk.word_counts.items()), key = lambda x: x[1]) if d[1] > 4]) + 1
          token = Tokenizer(n)
          token.fit_on_texts(t_x)
          token_t_x = token.texts_to_sequences(t_x)
          token_tt_x = token.texts_to_sequences(tt_x)
          token_v_x = token.texts_to_sequences(v_x)
          
          drop_train = [index for index, sentence in enumerate(token_t_x) if len(sentence) < 1]
          drop_test = [index for index, sentence in enumerate(token_tt_x) if len(sentence) < 1]
          drop_val = [index for index, sentence in enumerate(token_v_x) if len(sentence) < 1]
          
          token_t_x = np.delete(token_t_x, drop_train, axis=0)
          t_y = np.delete(t_y, drop_train, axis=0)
          token_tt_x = np.delete(token_tt_x, drop_test, axis=0)
          tt_y = np.delete(tt_y, drop_test, axis=0)
          token_v_x = np.delete(token_v_x, drop_val, axis=0)
          v_y = np.delete(v_y, drop_val, axis=0)
          
          w_l = len(pad_sequences(token_t_x)[0])
          train_inputs = pad_sequences(token_t_x, maxlen = w_l)
          test_inputs = pad_sequences(token_tt_x, maxlen = w_l)
          val_inputs = pad_sequences(token_v_x, maxlen = w_l)
          train_outputs = t_y
          test_outputs = tt_y
          val_outputs = v_y
          
          return train_inputs, val_inputs, test_inputs, train_outputs, val_outputs, test_outputs, n
  ```

  <br/>

- 설명

  ![j1](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j1.png?raw=true)

  <br/>

  - 사용할 패키지들

  ![j2](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j2.png?raw=true)

  - 클래스 생성, 데이터와 불용어 리스트를 매개변수로 받는다.
  - 클래스가 생성되면 인스턴스 객체로 데이터, 불용어 리스트를 만든다.
  - 그 후 데이터에 존재하는 빈 값, 중복되는 데이터를 제거한다.

  <br/>

  ![j3](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j3.png?raw=true)

  - 현재 데이터 모습을 확인하기 위한 테스트용 메소드

  <br/>

  ![j4](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j4.png?raw=true)

  - 전처리 메소드. 학습에 사용할 X데이터의 열 이름, 불용어 처리 여부를 매개변수로 받는다.

  - 메소드 안에 preprocessing함수를 구현한다.

    - Beautifulsoup로 마크업 언어 제거, 정규표현식으로 영어가 아닌 것들을 제거해준다.

    - 그 후 소문자화한 뒤 단어 토큰화해준다.

    - 불용어 처리 여부에 따라 불용어 처리를 한 뒤 단어로 나눠져 있는 문장을 스페이스바로 이어준다.

    - 완성된 문장을 반환한다.

  - 데이터의 x_data 열에 preprocessing함수를 적용한다.

  - 그 후 영어, 숫자 이외의 것들을 ''로 수정한다.

  - 스페이스바를 ''로 수정한다.

  - ''를 NaN값으로 변경한다.

  - dropna를 통해 NaN값을 가진 행을 모두 삭제한다.

  <br/>

  ![j5](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j5.png?raw=true)

  - 데이터 분류 메소드. 학습에 사용할 Y데이터의 열 이름, Y데이터가 문자열인지 아닌지, 이중분류문제인지 아닌지를 매개변수로 입력받는다.
  - Y데이터가 문자열이라면 LabelEncoder를 이용해 문자를 정수로 인코딩해준다.
  - 이중분류 문제라면 그대로 numpy array 모양으로 만들어 준다. 그 후 Y에 저장한다.
  - 다중분류 문제라면 to_categorical 메소드로 원-핫 인코딩해준다. 그 후 Y에 저장한다.
  - 'Clean_X' 열에 있는 데이터를 X에 저장한다.
  - 데이터를 분류한다. 먼저 7:3 비율로 데이터를 분류하고 7의 비율에 있던 데이터들을 다시 8:2 비율로 분류하여 테스트, 학습, 검증 데이터로 분류한다.
  - 학습 데이터로 Tokenizer를 통해 단어 vocabulary를 만든다.
  - 단어 빈도수가 5 이상인 단어의 수 + 1을 n에 저장한다. (1을 더하는 이유는 OOV 때문)
  - n만큼의 단어만 사용하도록 다시 vocabulary를 만든다.
  - t_x, tt_x, v_x를 vocabulary를 사용하여 단어에 맞는 정수값으로 만들어준다.
  - 이 과정에서 공백이 생긴 데이터의 인덱스를 파악한다.
  - 해당 인덱스로 테스트, 학습, 검증 데이터를 정리해준다.
  - 테스트 데이터에서 가장 긴 문장의 길이를 w_l에 저장한다.
  - w_l 길이를 최대로 각 x데이터들을 패딩한다.
  - 모두 정리된 테스트, 학습, 검증 데이터와 n을 반환한다. (n은 임배딩에서 사용)

<br/>

---

#### 실습(한글 데이터 전처리기를 클래스로 구현)

<br/>

- 코드

  ```python
  from konlpy.tag import Okt
  from tensorflow.keras.preprocessing.text import Tokenizer
  from tensorflow.keras.preprocessing.sequence import pad_sequences
  from sklearn.preprocessing import LabelEncoder
  from sklearn.model_selection import train_test_split
  from tensorflow.keras.utils import to_categorical
  import numpy as np
  import re
  import pandas as pd
  import numpy as np
  
  class Preprocessor_kor:
      def __init__(self, data, stop_words):
          self.data = data
          self.stop_w = stop_words
          self.X_data = []
      
      # 데이터 확인용
      def print_data(self):
          print(self.data)
      
      # 데이터의 NaN값을 지우는 메소드
      def remove_null(self):
          self.data = self.data.dropna(how = 'any')
          
      # 중복된 데이터를 지우는 메소드
      def remove_duplication(self, subset):
          self.data = self.data.drop_duplicates(subset = [subset])
          
      # 데이터 체크 메소드
      def ckeck_data(self):
          print(f'데이터 길이: \n{len(self.data)}')
          print()
          print(f'결측치 : \n{self.data.isnull().sum()}')
          print()
          print(f'중복 데이터 제외 : \n{self.data.nunique()}')
       
      # 불용어 추가 메소드
      def add_stop_words(self, stop_word):
          self.stop_w.add(stop_wrod)
         
      # 전처리 메소드(매개변수로 X_data로 학습할 열을 받음)
      def preprocessor(self, X):
          self.data['clean_X'] = self.data[X].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '')
          self.data['clean_X'] = self.data['clean_X'].str.replace('^ +', '')
          self.data['clean_X'] = self.data['clean_X'].replace('', np.nan)
          self.remove_null()
          okt = Okt()
          for i in self.data['clean_X']: 
              tk_d = okt.morphs(i) 
              end_d = [w for w in tk_d if not w in self.stop_w] 
              self.X_data.append(' '.join(end_d))
        
      # 분류기 메소드(매개변수로 Y_data로 학습할 열, Y_data가 문자열인지, Y_data가 이중분류 데이터인지를 받음)
      def data_classificator(self, Y_column, isstr = True, isbin = True): 
          if isstr:
              self.data['encoder_y'] = LabelEncoder().fit_transform(self.data[Y_column])
              if isbin:
                  Y = np.array(self.data['encoder_y'])
              else:
                  Y = to_categorical(self.data['encoder_y'])
          else:
              if isbin:
                  Y = np.array(self.data[Y_column])
              else:
                  Y = to_categorical(self.data[Y_column])
          X = np.array(self.X_data)
          
          x_data, tt_x, y_data, tt_y = train_test_split(X, Y, test_size = 0.3, random_state = 0)
          t_x, v_x, t_y, v_y = train_test_split(x_data, y_data, test_size = 0.2, random_state = 0)
          
          tk = Tokenizer()
          tk.fit_on_texts(t_x)
          n = len([d for d in sorted(list(tk.word_counts.items()), key = lambda x: x[1]) if d[1] > 4]) + 1
          
          token = Tokenizer(n)
          token.fit_on_texts(t_x)
          
          token_train_x = token.texts_to_sequences(t_x)
          token_test_x = token.texts_to_sequences(tt_x)
          token_val_x = token.texts_to_sequences(v_x)
          
          drop_train = [index for index, sentence in enumerate(token_train_x) if len(sentence) < 1]
          drop_test = [index for index, sentence in enumerate(token_test_x) if len(sentence) < 1]
          drop_val = [index for index, sentence in enumerate(token_val_x) if len(sentence) < 1]
          
          token_train_x = np.delete(token_train_x, drop_train, axis = 0)
          t_y = np.delete(t_y, drop_train, axis = 0)
          token_test_x = np.delete(token_test_x, drop_test, axis = 0)
          tt_y = np.delete(tt_y, drop_test, axis = 0)
          token_val_x = np.delete(token_val_x, drop_val, axis = 0)
          v_y = np.delete(v_y, drop_val, axis = 0)
          
          w_l = len(pad_sequences(token_train_x)[0])
          train_inputs = pad_sequences(token_train_x, maxlen = w_l)
          test_inputs = pad_sequences(token_test_x, maxlen = w_l)
          val_inputs = pad_sequences(token_val_x, maxlen = w_l)
          train_outputs = t_y
          test_outputs = tt_y
          val_outputs = v_y
          
          return train_inputs, test_inputs, val_inputs, train_outputs, test_outputs, val_outputs, n
  ```

<br/>

- 설명

  ![j6](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j6.png?raw=true)

  - 사용할 패키지를 불러온다.

  <br/>

  ![j7](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j7.png?raw=true)

  - 클래스 생성. 데이터와 불용어 리스트를 매개변수로 받는다.
  - 클래스 객체가 생성되면 인스턴스 객체로 data, stop_w, X_data를 생성한다. 각각 데이터, 불용어 리스트, 전처리가 끝난 문장을 담는 리스트이다.

  <br/>

  ![j8](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j8.png?raw=true)

  - 현재 데이터 모습을 확인하기 위한 테스트용 메소드

  <br/>

  ![j9](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j9.png?raw=true)

  - 데이터의 null값을 가진 행을 삭제하는 메소드

  <br/>

  ![j10](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j10.png?raw=true)

  - 중복된 데이터 행을 삭제하는 메소드, 중복 데이터를 찾을 기준 열을 subset 매개변수로 입력받음

  <br/>

  ![j11](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j11.png?raw=true)

  - 데이터 체크용 메소드, 데이터 길이, 결측치 여부, 중복 데이터를 제외한 데이터 수를 보여준다.

  <br/>

  ![j12](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j12.png?raw=true)

  - 불용어 리스트에 불용어를 추가할 때 사용하는 메소드. 추가할 불용어를 stop_word 매개변수로 받는다.

  <br/>

  ![j13](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j13.png?raw=true)

  - 전처리 메소드. X데이터로 학습할 열을 X 매개변수로 입력받음
  - data[X]에 존재하는 데이터에서 한글을 제외한 것들을 ''로 변경하고 data['clean_X']에 저장한다.
  - data['clean_X']에 존재하는 스페이스바를 모두 ''로 변환
  - 그 후 존재하는 ''을 모두 NaN으로 변환한다.
  - remove_null 메소드를 호출하여 NaN값을 가진 행을 모두 삭제한다.
  - data['clean_X']의 데이터들을 형태소 분석하고 불용어 처리해준다.
  - 단어들로 흩어져있는 문장들을 스페이스바로 묶어 X_data에 추가한다.

  <br/>

  ![j14](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j14.png?raw=true)

  - 분류기 메소드. Y데이터로 학습할 열, Y데이터가 문자열인지 아닌지, 이중분류 문제인지 다중분류 문제인지 매개변수로 입력받는다.
  - 동작은 영어 전처리기 클래스와 동일하다.

<br/>

---

#### 실습(영어 데이터 전처리기를 사용해 모델 생성 및 학습 진행)

<br/>

![j15](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j15.png?raw=true)

- 사용할 패키지 불러오기
- import_ipynb 패키지를 사용하면 쥬피터 노트북으로 작성한 클래스를 사용할 수 있다. (pip install import_ipynb로 설치 후 사용)

<br/>

![j16](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j16.png?raw=true)

- 불러온 데이터 확인

<br/>

![j17](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j17.png?raw=true)

- 필요없는 데이터는 삭제해준다.

<br/>

![j18](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j18.png?raw=true)

- 불용어 리스트를 생성해준다.

<br/>

![j19](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j19.png?raw=true)

- 만들어둔 클래스를 활용해 데이터를 분류해준다.

<br/>

![j20](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j20.png?raw=true)

- 분류한 데이터들의 형상을 확인하여 잘 분류되었는지 확인

<br/>

![j21](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j21.png?raw=true)

- 모델의 하이퍼 파라미터 값을 미리 정해놓는다.

<br/>

![j22](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j22.png?raw=true)

- 콜백함수들을 정의해준다.

<br/>

![j23](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j23.png?raw=true)

- m1 모델을 생성한다.
- 단순 RNN셀을 사용하는 모델이다.
- 임배딩의 첫 파라미터 값으로는 데이터 분류에서 정의된 total_word_num을 사용한다.

<br/>

![j24](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j24.png?raw=true)

- m1 모델을 학습시킨다.

<br/>

![j25](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j25.png?raw=true)

- m2 모델을 생성한다.
- LSTM 셀을 사용하는 모델이다.

<br/>

![j26](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j26.png?raw=true)

- m3 모델을 생성한다.
- GRU 셀을 사용하는 모델이다.

<br/>

![j27](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j27.png?raw=true)

- m4 모델을 생성한다.
- 양방향 RNN을 사용하는 모델이다.

<br/>

![j28](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j28.png?raw=true)

- 각 모델의 테스트 데이터에 대한 점수이다.
- 데이터 전처리 과정과 모델 튜닝에 대해서는 정답이 없으니 위 과정들이 정답은 아니다
- 항상 입력되는 데이터에 맞게 전처리하고 모델 생성, 튜닝하는 것이 중요하다.

<br/>

---

#### 실습(한글 데이터 전처리기를 사용해 모델 생성 및 학습 진행)

<br/>

![j29](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j29.png?raw=true)

- 사용할 패키지를 불러온다.
- 이후 과정은 위 실습과 거의 동일하다.

<br/>

![j30](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j30.png?raw=true)

- 데이터를 불러온다.

<br/>

![j31](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j31.png?raw=true)

- 중복되는 데이터가 없는지 확인한다.
- 대략 900개 정도가 document 열에서 중복되는 것을 알 수 있다.

<br/>

  ![j32](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j32.png?raw=true)

- 불용어 리스트를 생성한다.

<br/>

![j33](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j33.png?raw=true)

- 만들어놓은 클래스를 불러와서 데이터를 분류한다.

<br/>

![j34](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j34.png?raw=true)

- 분류한 데이터의 형상을 확인하여 잘 분류되었는지 체크한다.

<br/>

![j35](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j35.png?raw=true)

- 모델의 하이퍼 파라미터값과 콜백 함수들을 미리 정의해둔다.

<br/>

![j36](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j36.png?raw=true)

- 단순 RNN셀을 사용하는 모델 m1을 생성하고 학습시킨다.

<br/>

![j37](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j37.png?raw=true)

- LSTM 셀을 사용하는 모델 m2를 생성하고 학습시킨다.

<br/>

![j38](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j38.png?raw=true)

- GRU 셀을 사용하는 모델 m3를 생성하고 학습시킨다.

<br/>

![j39](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j39.png?raw=true)

- 양방향 RNN을 사용하는 모델 m4를 생성하고 학습시킨다.

<br/>

![j40](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%2010/j40.png?raw=true)

- 각 모델들의 테스트 데이터에 대한 스코어값이다.
- 최소한의 전처리를 하고 모델 튜닝도 하지 않았기 때문에 스코어 값이 좋게 나오지는 않는다.
- 하지만 위 실습과 이번 실습으로 데이터 전처리의 과정과 모델 생성 및 학습 과정의 순서를 잘 익힐 수 있었다. 