# 통계기반 비정형 텍스트 분석 06

<br/>

#### 예제1

<br/>

![j1](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j1.png?raw=true)

![j2](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j2.png?raw=true)

- csv파일로 저장된 데이터를 불러온다.

<br/>

![j3](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j3.png?raw=true)

- 불러온 데이터는 이미 전처리되어 있는 데이터이기 때문에 바로 테스트, 검증 데이터로 분류해준다.
- 단층 퍼셉트론 다중분류 모델을 만들고 학습을 진행한다.

<br/>

![j4](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j4.png?raw=true)

- loss값과 val_loss값의 변화를 그래프로 시각화한 이미지이다.
- 두 그래프 모두 0으로 수렴하다가 발산하는 것을 볼 수 있다.
- 한 그래프가 아니라 두 그래프 모두 발산한다는 것은 모델이 잘못됐거나 데이터 전처리가 잘못됐을 가능성이 높다.
- 실제로 불러온 이 데이터는 Y_data가 103종류로 분류되는 것이 아니라(target데이터가 103종 중 하나) 103종류 중에 몇 개든 중복되어 분류되는 데이터이다(target 데이터가 103종 중 하나 이상).

<br/>

---

#### 예제2

<br/>

![j5](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j5.png?raw=true)

- 한국어로 작성된 영화 리뷰 데이터를 불러온다. m에는 column 이름으로 사용할 데이터를 저장해둔다.

<br/>

![j6](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j6.png?raw=true)

- 불러온 데이터로 데이터 프레임을 만들어준다.

<br/>

![j7](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j7.png?raw=true)

- 단어 토큰화 이전에 데이터프레임의 document 열에 있는 데이터들에 한글이 아닌 것들을 제거해준다.

<br/>

![j8](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j8.png?raw=true)

- 불용어로 사용할 데이터를 불러온다. 한국어 전처리에서 주로 사용하는 불용어들을 모아놓은 txt파일이다.

<br/>

![j9](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j9.png?raw=true)

- 형태소 단위로 토큰화를 진행한다. 길이가 1보다 짧거나 불용어인 경우 걸러준다.

<br/>

![j10](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j10.png?raw=true)

- 위의 과정으로 문장들이 (형태소 + 공백)의 모양으로 전처리되었다.
- tensorflow패키지의 Tokenizer 모듈을 사용해서 공백을 기준으로 단어 토큰화해준다.
- num_words 파라미터 값을 10000으로 설정해서 단어 인덱스 10000까지만 실제로 사용하도록 한다.
- *len(tfidf_v.vocabulary_)는 잘못입력된 코드*

<br/>

![j11](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j11.png?raw=true)

- p_data의 label 열의 값들을 Y_data로 저장한다
- Y_data를 원-핫 인코딩한다.

<br/>

![j12](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j12.png?raw=true)

- 토큰화된 ttk로 tk_d 즉, 리뷰들을 tfidf 벡터화시킨다.

<br/>

![j13](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j13.png?raw=true)

- 만들어진 데이터를 분류한다.

<br/>

![j14](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j14.png?raw=true)

- 멀티 퍼셉트론 이중분류 모델로 학습을 진행한다.
- 과적합을 예방하기위해 Dropout을 걸어준다.

<br/>

![j15](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j15.png?raw=true)

- loss값과 val_loss값의 변화 그래프이다.
- loss값은 0으로 수렴하는데 val_loss는 발산하고 있는 것을 확인할 수 있다.
- 이런 경우 모델의 선정은 옳게 했으나 데이터 전처리에서 문제가 발생한 것이다.
- 공백 데이터, 중복 데이터, 분류에 필요없는 데이터 등 필요없는 데이터들에 의해 발생한 과대적합이라 할 수 있다.

<br/>

---

#### 예제3

<br/>

![j16](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j16.png?raw=true)

- 예제 2에서 사용한 데이터를 불러온다.

<br/>

![j17](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j17.png?raw=true)

- 우선 결측치를 확인한다.
- 확인 결과 결측치는 존재하지 않는 것을 알 수 있다.

<br/>

![j18](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j18.png?raw=true)

- 그 다음은 중복된 리뷰를 확인한다.
- 중복된 리뷰란, 두 리뷰가 있을 때 서로 내용이 완벽히 일치하는 리뷰를 이야기한다. 복사 붙여넣기한 리뷰를 걸러주겠다는 것
- 50000개의 리뷰 중에 842개의 리뷰가 중복되는 리뷰라는 것을 확인할 수 있다.

<br/>

![j19](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j19.png?raw=true)

- drop_duplicates 메소드로 document 열에 있는 중복되는 리뷰를 제거해준다.
- p_data를 확인해보면 50000개의 리뷰에서 49158개의 리뷰로 줄어든 것을 볼 수 있다.

<br/>

![j20](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j20.png?raw=true)

- 예제2와 같이 한국어가 아닌 것들은 제거해준다.

<br/>

![j21](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j21.png?raw=true)

- p_data를 확인해보면 전처리 과정에서 공백 데이터가 생긴 것을 확인할 수 있다.
- 이 값은 NaN값이 아닌 공백이기 때문에 데이터가 없다고 생각하면 안된다.
- 공백을 처리해주지 않으면 학습에 방해가 되기 때문에 처리해주어야 한다.

<br/>

![j22](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j22.png?raw=true)

- 정규표현식으로 스페이스바가 포함된 공백에서 스페이스바를 제거해준다.
- '^ +' 는 스페이스바 이후에 어떤 문자가 오더라도 인식한다는 뜻

<br/>

![j23](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j23.png?raw=true)

- 정리된 공백들을 numpy.nan를 활용하여 NaN값으로 변경해준다.

<br/>

![j24](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j24.png?raw=true)

- isnull 메소드로 306개의 리뷰가 공백이라는 것을 알 수 있다.
- dropna 메소드로 NaN값이 있는 리뷰를 제거해준다.
- p_data를 확인하면 리뷰의 수가 줄어든 것을 볼 수 있다.

<br/>

![j25](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j25.png?raw=true)

- 이번 예제에서는 직접 불용어 리스트를 작성한다.
- 형태소 분석기를 만들어 놓는다.

<br/>

![j26](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j26.png?raw=true)

- 리뷰 한 문장 씩을 꺼내서 형태소 분석한다.
- 이 과정에서 불용어를 걸러준다.

<br/>

![j27](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j27.png?raw=true)

- Tokenizer를 통해 단어 토큰화를 해준다.

<br/>

![j28](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j28.png?raw=true)

- 만들어진 단어들의 개수는 총 54256개 이다.
- 이 단어들 중에는 모든 리뷰에서 한 번, 또는 두 번 정도로 아주 적게 나온 단어도 포함되어 있다.
- 이런 단어들은 대략 50000만 개의 리뷰 중에서 나올까 말까한 의미가 없는 단어라고 할 수 있다.

<br/>

![j29](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j29.png?raw=true)

- tk에 저장된 단어들의 카운트 정보를 꺼내어 리스트로 저장한다
- 그 리스트를 카운트를 기준으로 정렬한다
- 정렬된 리스트에서 4번 이하로 나온 단어들은 제거한다
- 이렇게 걸러준 단어의 수는 10419개로 50000개에 비해서 상당히 줄어든 것을 볼 수 있다.

<br/>

![j30](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j30.png?raw=true)

- 다시 토큰화를 진행한다.
- 이번에는 빈도 수를 기준으로 10419개의 단어만 실제로 사용하도록 Tokenizer의 파라미터값으로 설정한다.
- 만들어지는 단어 수는 54256개이지만 문장을 벡터화할 때는 10419번 까지의 단어만 사용한다.
- 리뷰에서의 단어들은 앞 순서의 단어가 뒤의 단어에게 영향을 주는 시퀀스 데이터이다. 그렇기 때문에 text_to_sequences 메소드를 사용하여 벡터화해준다.

<br/>

![j31](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j31.png?raw=true)

- numpy.unique를 사용하여 벡터화한 단어 데이터의 값들을 확인해본다.
- 지금까지의 전처리 과정에서 다시 공백 데이터가 발생한 것을 알 수 있다.

<br/>

![j32](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j32.png?raw=true)

- p_data를 사용해서 s_df 데이터 프레임을 만들어 준다.

<br/>

![j33](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j33.png?raw=true)

- enumerate 함수를 사용해서 ch_x를 (인덱스, 값) 모양으로 만들어준다.
- ch_x의 값들을 하나씩 꺼내며 값이 공백이라면(list이기 때문에 길이가 0이라면) 해당 데이터의 인덱스를 d_idx에 저장한다.

<br/>

![j34](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j34.png?raw=true)

- 공백 데이터 처리를 위해 numpy.array 형상으로 p_data.label을 Y_data로 만들어준다.
- 위에서 만들어 놓은 X_data와 Y_data의 길이를 확인하면 48852개로 동일한 것을 알 수 있다.
- X_data를 토큰화된 tk로 벡터화해준다.
- X_data와 Y_data에서 d_dix의 값에 해당하는 인덱스 행을 제거해준다(공백 데이터 제거).

<br/>

![j35](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j35.png?raw=true)

- 공백 데이터를 제거한 X_data와 Y_data의 수이다. 대략 300개의 데이터가 제거된 것을 볼 수 있다.
- 공백 데이터가 잘 제거되었는지 확인해본다.

<br/>

![j36](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j36.png?raw=true)

- 입력 데이터의 형상을 동일하게 만들어 주기 위해서 패딩을 해준다.
- ck1_data를 패딩해주니 길이 59인 문장으로 패딩되었다.
- 패딩한 데이터와 Y_data로 ck_df 데이터 프레임을 만들어준다.
- 데이터 프레임을 통해 만들어진 데이터와 타겟 데이터를 눈으로 확인할 수 있다.

<br/>

![j37](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j37.png?raw=true)

- Y_data를 원-핫 인코딩하여 ck1_y에 저장한다.

<br/>

![j38](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j38.png?raw=true)

- ck1_data와 ck1_y로 데이터를 분류해준다.
- shape으로 형상을 확인하여 입력, 출력 형상을 알아둔다.

<br/>

![j39](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j39.png?raw=true)

- 단층 퍼셉트론 이중분류 모델을 만들어 학습을 진행한다.

<br/>

![j40](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j40.png?raw=true)

- loss값과 val_loss값의 변화를 그래프로 표현해보면
- loss값과 val_loss값이 0으로 수렴하지 않고 멈춰있는 것을 볼 수 있다.

<br/>

![j41](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j41.png?raw=true)

- 문장들의 길이를 확인해본다.
- X_data(패딩 전 벡터화된 문장 데이터)의 값들을 하나씩 꺼내서 그 길이를 ck_n에 저장한다
- ck_n으로 그래프를 그려보면 대부분의 문장들이 30~35의 길이를 갖는 것을 볼 수 있다.

<br/>

![j42](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j42.png?raw=true)

- 이번에는 길이제한을 주어 X_data를 패딩한다.
- 35의 길이로 패딩한다.
- Y_data의 데이터들은 후에 작업을 위해 int타입으로 변경해준다.

<br/>

![j43](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j43.png?raw=true)

- 데이터들을 분류해주고
- 좋은 학습을 위해 임배딩을 진행해준다. (임배딩에 관한 것은 다음에 공부, 우선 사용해보기)
- 시퀀셜한 데이터를 사용하기 때문에 RNN 모델을 만들어 준다.

<br/>

![j44](https://github.com/Cheolyong-Kim/TIL/blob/master/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D/%ED%86%B5%EA%B3%84%EA%B8%B0%EB%B0%98%20%EB%B9%84%EC%A0%95%ED%98%95%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%B6%84%EC%84%9D%20image%206/j44.png?raw=true)

- loss값과 val_loss값의 변화 그래프
- 이번에도 val_loss가 발산하는 것을 볼 수 있다.
- 자세한 원인과 수정 방법은 단어 임배딩을 배우면서 공부해본다.